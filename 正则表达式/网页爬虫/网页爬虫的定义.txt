 网络爬虫，也叫网络蜘蛛(Web Spider)，如果把互联网比喻成一个蜘蛛网，Spider就是一只在网上爬来爬去的蜘蛛。网络爬虫就是根据网页的地址来寻找网页的，也就是URL。举一个简单的例子，我们在浏览器的地址栏中输入的字符串就是URL，例如：https://www.baidu.com/

    URL就是同意资源定位符(Uniform Resource Locator)，它的一般格式如下(带方括号[]的为可选项)：

    protocol :// hostname[:port] / path / [;parameters][?query]#fragment

    URL的格式由三部分组成：

    (1)protocol：第一部分就是协议，例如百度使用的就是https协议；

    (2)hostname[:port]：第二部分就是主机名(还有端口号为可选参数)，一般网站默认的端口号为80，例如百度的主机名就是www.baidu.com，这个就是服务器的地址;

    (3)path：第三部分就是主机资源的具体地址，如目录和文件名等。

    网络爬虫就是根据这个URL来获取网页信息的。

    1.urllib.request模块是用来打开和读取URLs的；

2.urllib.error模块包含一些有urllib.request产生的错误，可以使用try进行捕捉处理；

3.urllib.parse模块包含了一些解析URLs的方法；

4.urllib.robotparser模块用来解析robots.txt文本文件.它提供了一个单独的RobotFileParser类，通过该类提供的can_fetch()方法测试爬虫是否可以下载一个页面。

    我们使用urllib.request.urlopen()这个接口函数就可以很轻松的打开一个网站，读取并打印信息